{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import kipoi\n",
    "from kipoi_veff import score_variants\n",
    "import pandas as pd\n",
    "from kipoi_cadd.utils import load_pickle, decompose_variant_string, generate_intervals_file\n",
    "import pyarrow as pa\n",
    "from kipoi_cadd.writers import LmdbWriter\n",
    "from kipoi_cadd.readers import LmdbReader\n",
    "from kipoi_cadd.data import KipoiLmdbDataset\n",
    "from kipoi_cadd.data_utils import calculate_map_size\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from kipoi_veff.scores import Diff, LogitRef, Logit\n",
    "from kipoi import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DeepSea features from example files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"/s/project/kipoi-cadd/data/raw/v1.3/training_data/\"\n",
    "sample_intervals_file = \"/data/nasif12/home_if12/simancas/.kipoi/models/DeepSEA/variantEffects/downloaded/example_files/intervals_file\"\n",
    "sample_fasta_file = \"/data/nasif12/home_if12/simancas/.kipoi/models/DeepSEA/variantEffects/downloaded/example_files/fasta_file\"\n",
    "sample_vcf_file = \"/data/nasif12/home_if12/simancas/.kipoi/models/DeepSEA/variantEffects/downloaded/example_files/variants.vcf\"\n",
    "test_dir = \"/tmp/kipoi-veff/test_KipoiLmdbDataset/\"\n",
    "variant_ids_file = test_dir + \"variant_ids.pkl\"\n",
    "kipoi_features_dir = \"/s/project/kipoi-cadd/data/processed/v1.3/kipoi_features/\"\n",
    "intervals_file = kipoi_features_dir + \"intervals_10k.tsv\"\n",
    "fasta_file = \"/s/genomes/human/hg19/ensembl_GRCh37.p13_release75/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa\"\n",
    "shuff_10k_file = training_dir + \"ids_10k.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To trigger the download of sample intervals and sample fasta files, we have to do this:\n",
    "model = get_model('DeepSEA/variantEffects')\n",
    "pred = model.pipeline.predict_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 dna:chromosome chromosome:GRCh37:1:1:249250621:1 REF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_intervals = pd.read_csv(sample_intervals_file, sep='\\t', header=None, names=['chr', 'start', 'end'])\n",
    "\"\"\"\n",
    "with open(sample_fasta_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break\n",
    "\"\"\"\n",
    "sample_intervals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate intervals file for the variants of our interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ids = load_pickle(shuff_10k_file)\n",
    "generate_intervals_file(var_ids, intervals_file, use_chr_word=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('DeepSEA/variantEffects')\n",
    "dl_kwargs = {'intervals_file': intervals_file, 'fasta_file': fasta_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataloader and instantiate it\n",
    "dl = model.default_dataloader(**{'intervals_file': intervals_file, 'fasta_file': fasta_file, 'num_chr_fasta': True})\n",
    "it = dl.batch_iter(batch_size=64)\n",
    "preds = None\n",
    "for batch in it:\n",
    "    if preds is None:\n",
    "        preds = model.predict_on_batch(batch['inputs'])\n",
    "    else:\n",
    "        preds = np.concatenate([preds, model.predict_on_batch(batch['inputs'])], axis=0)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results with LMDBWriter for other Kipoi predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone script\n",
    "import kipoi\n",
    "from kipoi_cadd.writers import LmdbWriter\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from kipoi_veff.scores import Logit\n",
    "from kipoi import get_model\n",
    "\n",
    "example_files_dir = \"/data/ouga/home/ag_gagneur/simancas/Projects/kipoi-veff/tests/models/var_seqlen_model/\"\n",
    "test_dir = \"/tmp/kipoi-veff/test_KipoiLmdbDataset/\"\n",
    "\n",
    "sample_intervals_file = example_files_dir + \"example_files/variant_centered_intervals.tsv\"\n",
    "sample_fasta_file = example_files_dir + \"example_files/hg38_chr22.fa\"\n",
    "sample_vcf_file = example_files_dir + \"example_files/variants.vcf.gz\"\n",
    "gtf_file = example_files_dir + \"example_files/gencode_v25_chr22.gtf.pkl.gz\"\n",
    "preproc_transformer = example_files_dir + \"dataloader_files/encodeSplines.pkl\"\n",
    "lmdb_deep_sea = test_dir + \"lmdb_DeepSea\"\n",
    "\n",
    "model = get_model('DeepSEA/variantEffects')\n",
    "dl_kwargs = {'intervals_file': sample_intervals_file, 'fasta_file': sample_fasta_file, 'num_chr_fasta': False}\n",
    "dataloader = model.default_dataloader\n",
    "writer = LmdbWriter(lmdb_deep_sea, \"DeepSea_veff\")\n",
    "\n",
    "preds = sp.predict_snvs(model,\n",
    "                dataloader,\n",
    "                sample_vcf_file,\n",
    "                64,\n",
    "                num_workers=1,\n",
    "                dataloader_args=dl_kwargs,\n",
    "                evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
    "                return_predictions=True,\n",
    "                sync_pred_writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = KipoiLmdbDataset(lmdb_deep_sea, variant_ids_file)\n",
    "# ds.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DeepSea scores from CADD's variants\n",
    "We need:\n",
    "- fasta file\n",
    "- vcf file\n",
    "- intervals file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/kipoi-cadd2/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/humanDerived_InDels.vcf.gz\n",
      "/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/humanDerived_SNVs.vcf.gz\n",
      "/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/simulation_InDels.vcf.gz\n",
      "/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/simulation_SNVs.vcf.gz\n",
      "/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/out_merged.vcf.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1837498</th>\n",
       "      <td>1</td>\n",
       "      <td>379177</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837499</th>\n",
       "      <td>1</td>\n",
       "      <td>379274</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837500</th>\n",
       "      <td>1</td>\n",
       "      <td>379476</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837501</th>\n",
       "      <td>1</td>\n",
       "      <td>379631</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837502</th>\n",
       "      <td>1</td>\n",
       "      <td>379724</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        #CHROM     POS ID REF ALT\n",
       "1837498      1  379177  .   G   T\n",
       "1837499      1  379274  .   G   C\n",
       "1837500      1  379476  .   T   A\n",
       "1837501      1  379631  .   G   C\n",
       "1837502      1  379724  .   G   A"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge vcf files\n",
    "def concatenate_vcf_files(directory, output=None):\n",
    "    ext = \"vcf.gz\"\n",
    "    vcf = None\n",
    "    col_names = ['#CHROM', 'POS', 'ID', 'REF', 'ALT']\n",
    "    for f in get_all_files_extension(training_dir_hg37, ext):\n",
    "        if vcf is None:\n",
    "            vcf = pd.read_csv(f, sep='\\t', comment='#', names=col_names,\n",
    "                              dtypes={0:'str',\n",
    "                                      1:'int32',\n",
    "                                      2:'str',\n",
    "                                      3:'str',\n",
    "                                      4:'str'})\n",
    "        else:\n",
    "            vcf = pd.concat([vcf, \n",
    "                             pd.read_csv(f, sep='\\t', comment='#', names=col_names,\n",
    "                                         dtypes={0:'str',\n",
    "                                                 1:'int32',\n",
    "                                                 2:'str',\n",
    "                                                 3:'str',\n",
    "                                                 4:'str'})], ignore_index=True)\n",
    "        print(f)\n",
    "    # vcf.astype(dtype={'#CHROM':'object', 'POS':'int32', 'ID':'object', 'REF':'object', 'ALT':'object'})\n",
    "    vcf.sort_values(by=['#CHROM', 'POS'], inplace=True)\n",
    "    vcf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    vcf[\"QUAL\"] = ['.'] * vcf.shape[0]\n",
    "    vcf[\"FILTER\"] = ['.'] * vcf.shape[0]\n",
    "    vcf[\"INFO\"] = ['.'] * vcf.shape[0]\n",
    "    \n",
    "    if output is not None:\n",
    "        with open(output, 'w') as f:\n",
    "            f.write(\"##fileformat=VCFv4.0\\n\")\n",
    "        vcf.to_csv(output, sep='\\t', index=None, mode='a')\n",
    "    return vcf\n",
    "\n",
    "vcf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add QUAL FILTER INFO and file format rows\n",
    "all_original = \"/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/all.vcf.gz\"\n",
    "all_new = \"/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37/all_new.vcf\"\n",
    "\n",
    "with open(all_new, 'w') as f:\n",
    "    f.write(\"##fileformat=VCFv4.0\\n\")\n",
    "\n",
    "edit_df = pd.read_csv(all_original, sep=\"\\t\", header=0)\n",
    "edit_df[\"QUAL\"] = ['.'] * edit_df.shape[0]\n",
    "edit_df[\"FILTER\"] = ['.'] * edit_df.shape[0]\n",
    "edit_df[\"INFO\"] = ['.'] * edit_df.shape[0]\n",
    "edit_df.to_csv(all_new, sep=\"\\t\", index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.0#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
      "1\t379177\t.\tG\tT\t.\t.\t.\n",
      "1\t379274\t.\tG\tC\t.\t.\t.\n",
      "1\t379476\t.\tT\tA\t.\t.\t.\n",
      "1\t379631\t.\tG\tC\t.\t.\t.\n",
      "1\t379724\t.\tG\tA\t.\t.\t.\n",
      "1\t379938\t.\tA\tG\t.\t.\t.\n",
      "1\t380028\t.\tT\tC\t.\t.\t.\n",
      "1\t380576\t.\tA\tT\t.\t.\t.\n",
      "1\t380577\t.\tT\tTT\t.\t.\t.\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! cat {all_new} | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone script\n",
    "import os\n",
    "from kipoi_cadd.utils import concatenate_vcf_files\n",
    "\n",
    "training_dir_v14 = \"/s/project/kipoi-cadd/data/raw/v1.4/training_data/\"\n",
    "training_dir_hg37 = os.path.join(training_dir_v14, \"GRCh37\")\n",
    "\n",
    "concatenate_vcf_files(training_dir_hg37, output=os.path.join(training_dir_hg37, \"all.vcf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33496006</th>\n",
       "      <td>X</td>\n",
       "      <td>224538</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33496007</th>\n",
       "      <td>X</td>\n",
       "      <td>224658</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33496008</th>\n",
       "      <td>X</td>\n",
       "      <td>224712</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33496009</th>\n",
       "      <td>X</td>\n",
       "      <td>224894</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33496010</th>\n",
       "      <td>X</td>\n",
       "      <td>224896</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         #CHROM     POS ID REF ALT\n",
       "33496006      X  224538  .   A   G\n",
       "33496007      X  224658  .   A   G\n",
       "33496008      X  224712  .   A   G\n",
       "33496009      X  224894  .   G   T\n",
       "33496010      X  224896  .   C   T"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = new_vcf.loc[new_vcf.loc[:,'#CHROM']==\"X\",:]\n",
    "x_df = x_df.iloc[:5].copy()\n",
    "tmp = new_vcf.loc[33292286:33292289,:].copy()\n",
    "new_tmp = pd.concat([x_df,tmp], ignore_index=True)\n",
    "new_tmp = new_tmp.astype(dtype={'#CHROM': 'str'})\n",
    "new_tmp.sort_values(by=['#CHROM', 'POS'])\n",
    "new_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vcf = new_vcf.astype(dtype={'#CHROM':'str', 'POS':'int32', 'ID':'str', 'REF':'str', 'ALT':'str'})\n",
    "new_vcf = new_vcf.sort_values(by=['#CHROM', 'POS'])\n",
    "new_vcf.to_csv(os.path.join(training_dir_hg37, \"all.vcf\"), sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the intervals file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate intervals file from vcf\n",
    "def generate_intervals_from_vcf(vcf,\n",
    "                                output=None,\n",
    "                                col_names=['#CHROM', 'POS', 'ID', 'REF', 'ALT'],\n",
    "                                dtypes={'#CHROM': 'str', 'POS': 'int32', 'ID': 'str', 'REF':'str', 'ALT':'str'}):\n",
    "    if isinstance(vcf, str):\n",
    "        vcf = pd.read_csv(vcf,\n",
    "                          sep='\\t',\n",
    "                          dtypes=dtypes,\n",
    "                          header= None,\n",
    "                          names=col_names,\n",
    "                          usecols=range(len(col_names)),\n",
    "                          comment='#')\n",
    "    elif not isinstance(sparse_matrix, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be either a path to a vcf(.gz) file or an object of pd.DataFrame type.\")\n",
    "    \n",
    "    intervals = {'chr': [], 'start': [], 'end': []}\n",
    "    for _, row in tqdm(vcf.iterrows()):\n",
    "        intervals['chr'].append(row['#CHROM'])\n",
    "        intervals['start'].append(row['POS'] - 1)\n",
    "        intervals['end'].append((row['POS'] - 1) + len(row['REF']))\n",
    "    \n",
    "    df = pd.DataFrame(intervals, index=range(len(intervals['chr'])))\n",
    "    df.sort_values(by=['chr', 'start'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    if output is not None:\n",
    "        df.to_csv(output, sep='\\t', index=None, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Standalone script\n",
    "import os\n",
    "from kipoi_cadd.utils import generate_intervals_from_vcf\n",
    "\n",
    "training_dir_v14 = \"/s/project/kipoi-cadd/data/raw/v1.4/training_data/\"\n",
    "training_dir_hg37 = os.path.join(training_dir_v14, \"GRCh37\")\n",
    "\n",
    "res = generate_intervals_from_vcf(os.path.join(training_dir_hg37, \"humanDerived_InDels.vcf.gz\"), os.path.join(training_dir_hg37, \"intervals.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone script\n",
    "import kipoi\n",
    "from kipoi_cadd.writers import LmdbWriter\n",
    "import kipoi_veff.snv_predict as sp\n",
    "from kipoi_veff.scores import Logit\n",
    "from kipoi import get_model\n",
    "import os\n",
    "\n",
    "cadd_files_dir = \"/data/ouga/home/ag_gagneur/simancas/Projects/kipoi-veff/tests/models/var_seqlen_model/\"\n",
    "training_dir_hg37 = \"/s/project/kipoi-cadd/data/raw/v1.4/training_data/GRCh37\"\n",
    "intervals_file = os.path.join(training_dir_hg37, \"intervals.tsv\")\n",
    "fasta_file = \"/s/genomes/human/hg19/ensembl_GRCh37.p13_release75/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa\"\n",
    "vcf_file = os.path.join(training_dir_hg37, \"all.vcf.gz\")\n",
    "lmdb_deep_sea = os.path.join(training_dir_hg37, \"lmdb/lmdb_DeepSea_veff\")\n",
    "\n",
    "model = get_model(\"DeepSEA/variantEffects\")\n",
    "dl_kwargs = {'intervals_file': intervals_file, 'fasta_file': fasta_file, 'num_chr_fasta': True}\n",
    "dataloader = model.default_dataloader\n",
    "\n",
    "num_lines = len(load_pickle(os.path.join(training_dir_hg37, \"variant_ids/all.pkl\")))\n",
    "map_size = calculate_map_size(ds[0], num_lines, 1.9)\n",
    "writer = LmdbWriter(lmdb_deep_sea, \"DeepSea_veff\", map_size)\n",
    "\n",
    "sp.predict_snvs(model,\n",
    "                dataloader,\n",
    "                vcf_file,\n",
    "                64,\n",
    "                num_workers=64,\n",
    "                dataloader_args=dl_kwargs,\n",
    "                evaluation_function_kwargs={'diff_types': {'logit': Logit()}},\n",
    "                return_predictions=False,\n",
    "                sync_pred_writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274578419865"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_lines = len(load_pickle(os.path.join(training_dir_hg37, \"variant_ids/all.pkl\")))\n",
    "map_size = calculate_map_size(ds[0], num_lines, 1.9)\n",
    "map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kipoi-cadd2]",
   "language": "python",
   "name": "conda-env-kipoi-cadd2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
